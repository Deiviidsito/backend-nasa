"""
Validador de Fase 1 â€” Ingesta de datos (CleanSky Los Ãngeles)
Autor: David Ãlvarez  
Fecha: 2025-10-05

Este script valida que todos los datasets descargados (TEMPO, OpenAQ, IMERG, MERRA-2)
estÃ©n correctamente generados, legibles y contengan datos coherentes.
"""

import os
import sys
from pathlib import Path
from datetime import datetime
import hashlib

# Intentar importar dependencias cientÃ­ficas
try:
    import xarray as xr
    import pandas as pd
    import numpy as np
    SCIENTIFIC_LIBS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Dependencias cientÃ­ficas no disponibles: {e}")
    SCIENTIFIC_LIBS_AVAILABLE = False

# Rutas de archivos
DATA_DIR = Path(__file__).parent.parent / "data" / "zarr_store"
CHECKS = {
    "TEMPO": DATA_DIR / "tempo_no2.zarr",
    "TEMPO_DEMO": DATA_DIR / "tempo_no2_demo.csv",
    "OpenAQ": DATA_DIR / "openaq_latest.parquet", 
    "IMERG": DATA_DIR / "imerg_precip.zarr",
    "IMERG_DEMO": DATA_DIR / "imerg_precip_demo.csv",
    "MERRA-2": DATA_DIR / "merra2_temp.zarr",
    "MERRA2_DEMO": DATA_DIR / "merra2_weather_demo.csv",
}

def log(status: str, msg: str):
    """Log con timestamp y emoji."""
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}] {status} {msg}")

def validate_tempo(zarr_path: Path, demo_path: Path) -> bool:
    """Validar datos TEMPO NOâ‚‚."""
    if not SCIENTIFIC_LIBS_AVAILABLE:
        return validate_file_exists(demo_path, "TEMPO demo")
    
    # Intentar primero Zarr, luego demo CSV
    path_to_use = zarr_path if zarr_path.exists() else demo_path
    
    try:
        if path_to_use.suffix == '.zarr':
            ds = xr.open_zarr(path_to_use)
            # Verificar dimensiones espaciales
            has_lat = any(dim in ds.dims for dim in ['latitude', 'lat'])
            has_lon = any(dim in ds.dims for dim in ['longitude', 'lon']) 
            assert has_lat and has_lon, "Dimensiones espaciales faltantes"
            
            # Buscar variable NOâ‚‚
            no2_vars = [v for v in ds.data_vars if 'no2' in str(v).lower()]
            assert len(no2_vars) > 0, "No se encontrÃ³ variable NOâ‚‚"
            
            val = float(ds[no2_vars[0]].mean().item())
            assert val > 0, f"Valor medio de NOâ‚‚ invÃ¡lido: {val}"
            
            log("âœ”ï¸", f"TEMPO Zarr vÃ¡lido ({val:.2e} molec/cmÂ²)")
            
        else:  # CSV demo
            df = pd.read_csv(path_to_use)
            assert not df.empty, "Archivo CSV vacÃ­o"
            
            required_cols = ['latitude', 'longitude', 'no2_tropospheric_column']
            assert all(col in df.columns for col in required_cols), "Columnas faltantes"
            
            val = df['no2_tropospheric_column'].mean()
            assert val > 0, f"Valor medio de NOâ‚‚ CSV invÃ¡lido: {val}"
            
            log("âœ”ï¸", f"TEMPO CSV demo vÃ¡lido ({val:.2e} molec/cmÂ², {len(df)} puntos)")
            
        return True
        
    except Exception as e:
        log("âŒ", f"TEMPO error: {e}")
        return False

def validate_openaq(path: Path) -> bool:
    """Validar datos OpenAQ."""
    if not SCIENTIFIC_LIBS_AVAILABLE:
        return validate_file_exists(path, "OpenAQ")
    
    try:
        df = pd.read_parquet(path)
        assert not df.empty, "Archivo vacÃ­o"
        
        # Verificar columnas esenciales
        essential_cols = ['location_id', 'latitude', 'longitude', 'parameter', 'value']
        missing_cols = [col for col in essential_cols if col not in df.columns]
        assert not missing_cols, f"Columnas faltantes: {missing_cols}"
        
        # Verificar que hay valores vÃ¡lidos
        assert df['value'].notna().any(), "Todos los valores son nulos"
        
        # Verificar parÃ¡metros esperados
        params = df['parameter'].unique()
        expected_params = {'pm25', 'no2', 'o3'}
        found_params = set(params) & expected_params
        assert len(found_params) >= 2, f"ParÃ¡metros insuficientes: {params}"
        
        log("âœ”ï¸", f"OpenAQ vÃ¡lido ({len(df)} registros, parÃ¡metros: {list(params)})")
        return True
        
    except Exception as e:
        log("âŒ", f"OpenAQ error: {e}")
        return False

def validate_imerg(zarr_path: Path, demo_path: Path) -> bool:
    """Validar datos IMERG precipitaciÃ³n."""
    if not zarr_path.exists() and not demo_path.exists():
        log("âš ï¸", "IMERG no encontrado (opcional)")
        return True
    
    if not SCIENTIFIC_LIBS_AVAILABLE:
        return validate_file_exists(demo_path, "IMERG demo")
    
    path_to_use = zarr_path if zarr_path.exists() else demo_path
    
    try:
        if path_to_use.suffix == '.zarr':
            ds = xr.open_zarr(path_to_use)
            precip_vars = [v for v in ds.data_vars if any(term in str(v).lower() 
                          for term in ['rain', 'precip', 'precipitation'])]
            assert len(precip_vars) > 0, "No se encontrÃ³ variable de precipitaciÃ³n"
            
            val = float(ds[precip_vars[0]].mean().item())
            log("âœ”ï¸", f"IMERG Zarr vÃ¡lido ({precip_vars[0]}: {val:.3f} mm/hr)")
            
        else:  # CSV demo
            df = pd.read_csv(path_to_use)
            assert not df.empty, "Archivo CSV vacÃ­o"
            assert 'precipitation' in df.columns, "Columna precipitation faltante"
            
            val = df['precipitation'].mean()
            log("âœ”ï¸", f"IMERG CSV demo vÃ¡lido ({val:.3f} mm/hr, {len(df)} registros)")
            
        return True
        
    except Exception as e:
        log("âŒ", f"IMERG error: {e}")
        return False

def validate_merra2(zarr_path: Path, demo_path: Path) -> bool:
    """Validar datos MERRA-2 temperatura/viento."""
    if not zarr_path.exists() and not demo_path.exists():
        log("âš ï¸", "MERRA-2 no encontrado (opcional)")
        return True
    
    if not SCIENTIFIC_LIBS_AVAILABLE:
        return validate_file_exists(demo_path, "MERRA-2 demo")
    
    path_to_use = zarr_path if zarr_path.exists() else demo_path
    
    try:
        if path_to_use.suffix == '.zarr':
            ds = xr.open_zarr(path_to_use)
            required_vars = ["T2M", "U2M", "V2M"]
            missing_vars = [var for var in required_vars if var not in ds.data_vars]
            assert not missing_vars, f"Variables faltantes: {missing_vars}"
            
            # Verificar rangos razonables
            temp_mean = float(ds["T2M"].mean().item())
            assert 250 < temp_mean < 350, f"Temperatura irreal: {temp_mean} K"
            
            log("âœ”ï¸", f"MERRA-2 Zarr vÃ¡lido (T2M: {temp_mean:.1f} K)")
            
        else:  # CSV demo
            df = pd.read_csv(path_to_use)
            assert not df.empty, "Archivo CSV vacÃ­o"
            
            required_cols = ['T2M', 'U2M', 'V2M']
            missing_cols = [col for col in required_cols if col not in df.columns]
            assert not missing_cols, f"Columnas faltantes: {missing_cols}"
            
            temp_mean = df['T2M'].mean()
            assert 250 < temp_mean < 350, f"Temperatura irreal: {temp_mean} K"
            
            log("âœ”ï¸", f"MERRA-2 CSV demo vÃ¡lido (T2M: {temp_mean:.1f} K, {len(df)} registros)")
            
        return True
        
    except Exception as e:
        log("âŒ", f"MERRA-2 error: {e}")
        return False

def validate_file_exists(path: Path, name: str) -> bool:
    """ValidaciÃ³n bÃ¡sica de existencia de archivo."""
    if path.exists():
        size_kb = path.stat().st_size / 1024
        log("âœ”ï¸", f"{name} existe ({size_kb:.1f} KB)")
        return True
    else:
        log("âŒ", f"{name} no encontrado: {path}")
        return False

def validate_data_consistency() -> bool:
    """Validar consistencia entre datasets."""
    if not SCIENTIFIC_LIBS_AVAILABLE:
        log("âš ï¸", "ValidaciÃ³n de consistencia omitida (dependencias)")
        return True
    
    try:
        # Verificar que todos usan el mismo bounding box aproximado
        bbox_checks = []
        
        # OpenAQ
        if CHECKS["OpenAQ"].exists():
            df = pd.read_parquet(CHECKS["OpenAQ"])
            if not df.empty:
                lat_range = (df['latitude'].min(), df['latitude'].max())
                lon_range = (df['longitude'].min(), df['longitude'].max())
                bbox_checks.append(('OpenAQ', lat_range, lon_range))
        
        # TEMPO demo
        if CHECKS["TEMPO_DEMO"].exists():
            df = pd.read_csv(CHECKS["TEMPO_DEMO"])
            lat_range = (df['latitude'].min(), df['latitude'].max())
            lon_range = (df['longitude'].min(), df['longitude'].max())
            bbox_checks.append(('TEMPO', lat_range, lon_range))
        
        if len(bbox_checks) >= 2:
            # Verificar que los rangos se solapan (estÃ¡n en LA)
            for name, (lat_min, lat_max), (lon_min, lon_max) in bbox_checks:
                assert 33 <= lat_min <= 35, f"{name}: latitud fuera de LA"
                assert 34 <= lat_max <= 35, f"{name}: latitud fuera de LA"
                assert -119 <= lon_min <= -117, f"{name}: longitud fuera de LA"
                assert -119 <= lon_max <= -117, f"{name}: longitud fuera de LA"
        
        log("âœ”ï¸", "Consistencia geogrÃ¡fica validada (todos en LA)")
        return True
        
    except Exception as e:
        log("âš ï¸", f"ValidaciÃ³n de consistencia: {e}")
        return True  # No crÃ­tico

def validate_reproducibility() -> bool:
    """Validar que los archivos son estables."""
    try:
        # Calcular checksums de archivos existentes
        checksums = {}
        for name, path in CHECKS.items():
            if path.exists():
                with open(path, 'rb') as f:
                    content = f.read()
                checksums[name] = hashlib.md5(content).hexdigest()[:8]
        
        if checksums:
            log("âœ”ï¸", f"Checksums calculados: {len(checksums)} archivos")
            return True
        else:
            log("âš ï¸", "No hay archivos para validar reproducibilidad")
            return True
            
    except Exception as e:
        log("âš ï¸", f"ValidaciÃ³n de reproducibilidad: {e}")
        return True  # No crÃ­tico

def main():
    """Ejecutar validaciÃ³n completa de Fase 1."""
    log("ğŸš€", "Iniciando validaciÃ³n de Fase 1 â€” Ingesta de datos CleanSky LA")
    log("ğŸ“", f"Directorio de datos: {DATA_DIR}")
    
    # Verificar que el directorio existe
    if not DATA_DIR.exists():
        log("âŒ", f"Directorio de datos no existe: {DATA_DIR}")
        return False
    
    # Listar archivos disponibles
    files = list(DATA_DIR.glob('*'))
    log("ğŸ“‚", f"Archivos encontrados: {len(files)}")
    for f in files:
        size_kb = f.stat().st_size / 1024
        log("  ", f"  {f.name} ({size_kb:.1f} KB)")
    
    # Ejecutar validaciones por dataset
    results = {}
    
    log("ğŸ›°ï¸", "Validando TEMPO NOâ‚‚...")
    results["TEMPO"] = validate_tempo(CHECKS["TEMPO"], CHECKS["TEMPO_DEMO"])
    
    log("ğŸŒ«ï¸", "Validando OpenAQ...")
    results["OpenAQ"] = validate_openaq(CHECKS["OpenAQ"])
    
    log("ğŸŒ§ï¸", "Validando IMERG precipitaciÃ³n...")
    results["IMERG"] = validate_imerg(CHECKS["IMERG"], CHECKS["IMERG_DEMO"])
    
    log("ğŸŒ¡ï¸", "Validando MERRA-2 meteorologÃ­a...")
    results["MERRA-2"] = validate_merra2(CHECKS["MERRA-2"], CHECKS["MERRA2_DEMO"])
    
    # Validaciones adicionales
    log("ğŸ”", "Validando consistencia de datos...")
    consistency_ok = validate_data_consistency()
    
    log("ğŸ”„", "Validando reproducibilidad...")
    reproducibility_ok = validate_reproducibility()
    
    # Calcular resultado final
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    # Determinar status final
    if passed == total:
        status = "âœ… Ã‰XITO TOTAL"
        message = "Fase 1 completada con Ã©xito: todos los datasets legibles y coherentes."
    elif passed >= 3:
        status = "âš ï¸ PARCIAL"
        message = "Datos vÃ¡lidos parcialmente: revisar fuentes fallidas."
    else:
        status = "âŒ FALLA"
        message = "Fase 1 invÃ¡lida: revisar logs y repetir la ingesta."
    
    # Reporte final
    log("ğŸ“Š", f"Resultado: {status} ({passed}/{total})")
    log("ğŸ¯", message)
    
    # Detalles por dataset
    log("ğŸ“‹", "Detalle por dataset:")
    for name, success in results.items():
        icon = "âœ…" if success else "âŒ"
        log("  ", f"  {icon} {name}")
    
    # Recomendaciones
    if status == "âœ… Ã‰XITO TOTAL":
        log("ğŸš€", "ğŸ‰ Â¡LISTO PARA FASE 2: Procesamiento y fusiÃ³n de datos!")
        log("ğŸ’¡", "Siguiente paso: Implementar pipeline de procesamiento")
    elif status == "âš ï¸ PARCIAL":
        failed = [name for name, success in results.items() if not success]
        log("ğŸ”§", f"Revisar datasets fallidos: {failed}")
        log("ğŸ’¡", "OpenAQ es crÃ­tico, otros pueden ser opcionales")
    else:
        log("ğŸš«", "Repetir ingesta completa antes de continuar")
    
    return status == "âœ… Ã‰XITO TOTAL"

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)